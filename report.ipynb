{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yur1j27zVwwc"
   },
   "source": [
    "# ATML report\n",
    "## Music genre recognition\n",
    "Authors:\n",
    "- Dorian Guyot\n",
    "- Jonathan Péclat\n",
    "- Thomas Schaller\n",
    "\n",
    "Goal : ...\n",
    "\n",
    "## Approach description\n",
    "\n",
    "\n",
    "## Folder structure\n",
    "```\n",
    "ATML19\n",
    "│   README.md : Simple readme for github\n",
    "│   report.ipynb : Project report (this file)\n",
    "│   report.html : Same as report.ipynb but in HTML format\n",
    "│   pres.pdf : The pdf of the presentation\n",
    "│\n",
    "└─── notebooks : Notebook's files where tests were made\n",
    "│   │   create_data_folder.ipynb : Create data folder when spectrogram are created\n",
    "│   │   model_dorian.ipynb : Testing differents models on data\n",
    "│   │   model_thomas.ipynb : Testing differents models on data\n",
    "│   │   spectrogram.ipynb : Creating spectrograms from wav files\n",
    "│   │   generate_experiments.ipynb : Generate a barplot from genre classification on external wav's musics.\n",
    "│   │   src_python : Contains scripts use in generate_experiments (same as test_src)\n",
    "│   \n",
    "└─── test_src : Small app to test the final model\n",
    "│   │   user_app.py : Main file of the app\n",
    "│   └─── generate_data : Folder containing the file to create the spectogram of the music\n",
    "│   │    │ spectrogram.py : Class to create the spectrogram of the music\n",
    "│   │\n",
    "│   └─── models : Folder containing files for the model\n",
    "│   │    │ best_model_resnet : State dict of the best model created with resnet\n",
    "│   │    │ model.py : Model of the project. Allow to predict genre of music\n",
    "│   \n",
    "└─── train_src : Small app to test the final model\n",
    "│   │   main.py : Main file of the app to train the model\n",
    "│   └─── generate_data : Folder containing files to process the data and create the data directory.\n",
    "│   │    │ data_folder.py : Create the data folder to be able to use ImageFolder from pytorch then.\n",
    "│   │    │ spectrogram.py : Create the spectrograms of all musics contain in a folder.\n",
    "│   │\n",
    "│   └─── model : Folder containing files for training the model\n",
    "│   │    │ dataloader.py : Create the dataloader with the data of the data directory\n",
    "│   │    │ model.py : train the model with the dataloader and save the best one\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aybHDmezI_ze"
   },
   "source": [
    "# Results\n",
    "table results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30ci9aVtI8TN"
   },
   "source": [
    "## Example of use\n",
    "\n",
    "Before using our work, you need to download some data. You can either download the wav and do the processing by ourself with our app, or directly download the data which were already processed. The data folder contains spectrograms of the wav files. Here is the link to download the two folders: https://www.dropbox.com/sh/dg1crj9yimefgpb/AADcOLk9fkLxFbaO7dn-rACDa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyEzTZjnVwwn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NCSNMHyWp0x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuu231wZWqFi"
   },
   "source": [
    "## Generating experiments\n",
    "For information, the code below can also be found in the notebook `generate_experiments`.\n",
    "\n",
    "The folder containing the music to be processed below is located at the root of the project under the name `test_data`.\n",
    "\n",
    "To begin with, we must make the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLuC86vpWraB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from test_src.generate_data.spectrogram import Spectrogram\n",
    "from test_src.models.model import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3n29n2lazjS"
   },
   "source": [
    "Then, we must list the music in the designated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j-DJdzoa1BN"
   },
   "outputs": [],
   "source": [
    "experiments_folder = 'test_data'\n",
    "styles = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM5fOMqra1pn"
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for file in os.listdir(experiments_folder):\n",
    "    if os.path.isdir(os.path.join(experiments_folder, file)):\n",
    "        for file2 in os.listdir(os.path.join(experiments_folder, file)):\n",
    "            if os.path.isfile(os.path.join(experiments_folder,file,file2)):\n",
    "                test_data.append([file, file2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXVT0xdMa3zD"
   },
   "source": [
    "Then we have to create the two classes that will be used to create the spectrograms as well as to predict the genre of the music. For the model, we will use the best model we have found, which is the one realized with transfer learning and resnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tHKcdewa5DN"
   },
   "outputs": [],
   "source": [
    "model_dict_path = \"test_src/models/best_model_resnet\"\n",
    "model = Model()\n",
    "model.load(model_dict_path)\n",
    "spectrogram = Spectrogram()\n",
    "length_data = len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DK8khyzQa6W9"
   },
   "source": [
    "Finally, we will generate for each of the musics its corresponding spectrograms, and predict with the model what is the genre of the music. Then, to better visualize the result, a BarPlot was created with the percentage obtained for each of the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jK-2Vzw-a7hu"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for data in test_data:\n",
    "    print(\"Processing music \",i,\"/\",length_data)\n",
    "    imgs = spectrogram.sample(os.path.join(experiments_folder,data[0],data[1]))\n",
    "    results_sum = np.array([0.0] * len(styles))\n",
    "    for img in imgs:\n",
    "        results_sum += model.predict_image(img)\n",
    "    results = results_sum / len(imgs) * 100.0\n",
    "    y_pos = np.arange(len(styles))\n",
    "    plt.bar(y_pos, results, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, styles, rotation=45)\n",
    "    plt.ylim([0,100])\n",
    "    plt.ylabel('Percent')\n",
    "    plt.title('Title: '+data[1]+', True genre: '+data[0])\n",
    "    plt.show()\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
