{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_thomas.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5DgHeMStHTGi","colab_type":"code","outputId":"dfb5b735-99ba-434d-c502-4aed49c82b2e","executionInfo":{"status":"ok","timestamp":1557408172263,"user_tz":-120,"elapsed":26066,"user":{"displayName":"Thomas Schaller","photoUrl":"","userId":"04727138696451947462"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v5nGEGbgG_ts","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kguspuzZG_uG","colab_type":"code","colab":{}},"source":["from torchvision.datasets import ImageFolder\n","from torchvision.transforms import Resize, ToTensor, Normalize, Compose, Grayscale, ColorJitter\n","from torch.utils.data import DataLoader\n","batch_size = 100\n","data_dir = '/content/drive/My Drive/ATML/data/'\n","root_dir = data_dir + 'train'\n","\n","target_size = (100,100)\n","transforms = Compose([\n","                    Grayscale(num_output_channels=1),\n","                    ColorJitter(brightness=0.2,contrast=0.2),\n","                   # Resize(target_size), # Resizes image\n","                    ToTensor(),           # Converts to Tensor, scales to [0, 1] float (from [0, 255] int)\n","                    Normalize((0.5,), (0.5,)), # scales to [-1.0, 1.0]\n","                    ])\n","\n","train_dataset = ImageFolder(root_dir, transform=transforms)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xMWjH4OG_uS","colab_type":"code","colab":{}},"source":["# Same for validation dataset\n","val_root_dir = data_dir + 'val'\n","val_dataset = ImageFolder(val_root_dir, transform=transforms)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LHE-KWsG_ud","colab_type":"code","colab":{}},"source":["# Same for test dataset\n","test_root_dir = data_dir + 'test'\n","test_dataset = ImageFolder(test_root_dir, transform=transforms)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7fqa1WlG_up","colab_type":"code","outputId":"a0c025c2-f437-40a1-9a21-03e0a39e0361","executionInfo":{"status":"ok","timestamp":1557411448475,"user_tz":-120,"elapsed":435,"user":{"displayName":"Thomas Schaller","photoUrl":"","userId":"04727138696451947462"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(train_dataset[0][0].shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["torch.Size([1, 216, 216])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0evvTKzBG_uw","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","    \n","class ConvNet(nn.Module):\n","    \n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv = nn.Sequential(\n","          # input: 1x216x216\n","          nn.Conv2d(1, 64, 5),\n","          # output: 64x212x212\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2, 2),\n","          # output: 64x106x106\n","          nn.Conv2d(64, 64, 5),\n","          # output: 64x102x102\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2, 2),\n","          # output: 64x51x51\n","          nn.Conv2d(64, 64, 4),\n","          # output: 64x48x48\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2, 2),\n","          # output: 64x24x24\n","          nn.Conv2d(64, 64, 5),\n","          # output: 64x20*20\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2, 2),\n","          # output: 64x10*10\n","        )\n","        self.fc = nn.Sequential(\n","          nn.Linear(64*10*10,364),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(364,192),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(192,10)\n","        )\n","    \n","    def forward(self, input):\n","        output = self.conv(input)\n","        output = output.view(output.size(0), 64*10*10)\n","        output = self.fc(output)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jAYsMw4G_u5","colab_type":"code","colab":{}},"source":["# ADDING EARLY STOPPING\n","import numpy as np\n","import torch\n","from copy import deepcopy\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","def train(model, train_loader, optimizer, loss_fn, print_every=100):\n","    '''\n","    Trains the model for one epoch\n","    '''\n","    model.train()\n","    losses = []\n","    n_correct = 0\n","    for iteration, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        output = model(images)\n","        optimizer.zero_grad()\n","        loss = loss_fn(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","#         if iteration % print_every == 0:\n","#             print('Training iteration {}: loss {:.4f}'.format(iteration, loss.item()))\n","        losses.append(loss.item())\n","        n_correct += torch.sum(output.argmax(1) == labels).item()\n","    accuracy = 100.0 * n_correct / len(train_loader.dataset)\n","    return np.mean(np.array(losses)), accuracy\n","            \n","def test(model, test_loader, loss_fn):\n","    '''\n","    Tests the model on data from test_loader\n","    '''\n","    model.eval()\n","    test_loss = 0\n","    n_correct = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            output = model(images)\n","            loss = loss_fn(output, labels)\n","            test_loss += loss.item()\n","            n_correct += torch.sum(output.argmax(1) == labels).item()\n","\n","    average_loss = test_loss / len(test_loader)\n","    accuracy = 100.0 * n_correct / len(test_loader.dataset)\n","#     print('Test average loss: {:.4f}, accuracy: {:.3f}'.format(average_loss, accuracy))\n","    return average_loss, accuracy\n","\n","\n","def fit(train_dataloader, val_dataloader, model, optimizer, loss_fn, n_epochs, scheduler=None):\n","    train_losses, train_accuracies = [], []\n","    val_losses, val_accuracies = [], []\n","    best_val_loss = np.inf\n","    val_accuracy_best = 0\n","    best_model = None\n","    patience = 5 # if no improvement after 5 epochs, stop training\n","    counter = 0\n","    for epoch in range(n_epochs):\n","        train_loss, train_accuracy = train(model, train_dataloader, optimizer, loss_fn)\n","        val_loss, val_accuracy = test(model, val_dataloader, loss_fn)\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_accuracy)\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_accuracy)\n","        if scheduler:\n","            scheduler.step() # argument only needed for ReduceLROnPlateau\n","        print('Epoch {}/{}: train_loss: {:.4f}, train_accuracy: {:.4f}, val_loss: {:.4f}, val_accuracy: {:.4f}'.format(epoch+1, n_epochs,\n","                                                                                                          train_losses[-1],\n","                                                                                                          train_accuracies[-1],\n","                                                                                                          val_losses[-1],\n","                                                                                                          val_accuracies[-1]))\n","        ### Early stopping code\n","        if val_accuracy > val_accuracy_best:\n","            best_val_loss = val_loss\n","            val_accuracy_best = val_accuracy\n","            best_model = deepcopy(model)\n","            counter = 0\n","        else:\n","            counter += 1\n","        if counter == patience and False:\n","            print('No improvement for {} epochs; training stopped.'.format(patience))\n","            break\n","    \n","    return best_val_loss, val_accuracy_best"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQvNYUi9G_vB","colab_type":"code","colab":{}},"source":["model_conv = ConvNet()\n","model_conv = model_conv.to(device)\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(model_conv.parameters(), lr=learning_rate, weight_decay=0.004)\n","n_epochs = 25\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVAAWWPgG_vN","colab_type":"code","outputId":"5bd80a94-5c54-43b7-b618-87dd20f82984","executionInfo":{"status":"ok","timestamp":1557224727176,"user_tz":-120,"elapsed":197623,"user":{"displayName":"Thomas Schaller","photoUrl":"","userId":"04727138696451947462"}},"colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["val_loss, val_accuracy = fit(train_dataloader, val_dataloader, model_conv, optimizer, loss_fn, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/25: train_loss: 2.4935, train_accuracy: 10.0000, val_loss: 2.3419, val_accuracy: 10.0000\n","Epoch 2/25: train_loss: 2.7547, train_accuracy: 8.2222, val_loss: 3.0683, val_accuracy: 10.6667\n","Epoch 3/25: train_loss: 2.1891, train_accuracy: 27.8889, val_loss: 9.3977, val_accuracy: 10.0000\n","Epoch 4/25: train_loss: 2.6505, train_accuracy: 28.6667, val_loss: 5.1078, val_accuracy: 10.0000\n","Epoch 5/25: train_loss: 2.0266, train_accuracy: 38.2778, val_loss: 20.2907, val_accuracy: 10.0000\n","Epoch 6/25: train_loss: 7.4725, train_accuracy: 18.2222, val_loss: 3.6653, val_accuracy: 11.3333\n","Epoch 7/25: train_loss: 2.9744, train_accuracy: 24.6667, val_loss: 2.3443, val_accuracy: 11.0000\n","Epoch 8/25: train_loss: 3.0941, train_accuracy: 9.8333, val_loss: 6.7081, val_accuracy: 10.0000\n","Epoch 9/25: train_loss: 2.6864, train_accuracy: 17.8333, val_loss: 31.3317, val_accuracy: 10.0000\n","Epoch 10/25: train_loss: 3.4473, train_accuracy: 9.5000, val_loss: 3.3121, val_accuracy: 10.0000\n","Epoch 11/25: train_loss: 3.3247, train_accuracy: 4.0556, val_loss: 2.3589, val_accuracy: 10.6667\n","No improvement for 5 epochs; training stopped.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ylMqWHDWG_vf","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","    \n","class Conv1DNet(nn.Module):\n","    \n","    def __init__(self):\n","        super(Conv1DNet, self).__init__()\n","        self.conv = nn.Sequential(\n","          # input: 1x216x216\n","          nn.Conv2d(1, 64, (5,1)),\n","          # output: 64x212x216\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.ReLU(),\n","          nn.MaxPool2d((2,1), (2,1)),\n","          nn.Dropout(0.5),\n","          # output: 64x106x216\n","          nn.Conv2d(64, 64, (5,1)),\n","          # output: 64x102x216\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.ReLU(),\n","          nn.MaxPool2d((2,1), (2,1)),\n","          nn.Dropout(0.5),\n","          # output: 64x51x216\n","          nn.Conv2d(64, 64, (4,1)),\n","          # output: 64x48x216\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.ReLU(),\n","          nn.MaxPool2d((2,1), (2,1)),\n","          nn.Dropout(0.5),\n","          # output: 64x24x216\n","          nn.Conv2d(64, 64, (5,1)),\n","          # output: 64x20x216\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.ReLU(),\n","          nn.MaxPool2d((2,1), (2,1)),\n","          nn.Dropout(0.5)\n","          # output: 64x10x216\n","        )\n","        self.fc = nn.Sequential(\n","          nn.Linear(64*10*216,364),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(364,192),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(192,10)\n","        )\n","    \n","    def forward(self, input):\n","        output = self.conv(input)\n","        output = output.view(output.size(0), 64*10*216)\n","        output = self.fc(output)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbC84f4EOYSR","colab_type":"code","colab":{}},"source":["model_conv = Conv1DNet()\n","model_conv = model_conv.to(device)\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(model_conv.parameters(), lr=learning_rate)\n","n_epochs = 50\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"of3VYXXDOakW","colab_type":"code","outputId":"ee0e8344-e64c-4424-b936-a2b5f06535c5","executionInfo":{"status":"ok","timestamp":1557238100150,"user_tz":-120,"elapsed":1287152,"user":{"displayName":"Thomas Schaller","photoUrl":"","userId":"04727138696451947462"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["val_loss, val_accuracy = fit(train_dataloader, val_dataloader, model_conv, optimizer, loss_fn, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/50: train_loss: 39.1402, train_accuracy: 9.2222, val_loss: 21.6251, val_accuracy: 10.0000\n","Epoch 2/50: train_loss: 20.2774, train_accuracy: 2.1667, val_loss: 8.2255, val_accuracy: 9.6667\n","Epoch 3/50: train_loss: 10.4945, train_accuracy: 1.8333, val_loss: 2.7083, val_accuracy: 13.6667\n","Epoch 4/50: train_loss: 4.7679, train_accuracy: 3.6667, val_loss: 2.3164, val_accuracy: 18.3333\n","Epoch 5/50: train_loss: 3.6239, train_accuracy: 5.0556, val_loss: 2.3173, val_accuracy: 13.6667\n","Epoch 6/50: train_loss: 3.3256, train_accuracy: 5.1667, val_loss: 2.2237, val_accuracy: 23.0000\n","Epoch 7/50: train_loss: 2.9765, train_accuracy: 6.5556, val_loss: 2.2480, val_accuracy: 15.0000\n","Epoch 8/50: train_loss: 2.7924, train_accuracy: 7.3333, val_loss: 2.2407, val_accuracy: 19.0000\n","Epoch 9/50: train_loss: 2.7316, train_accuracy: 7.7222, val_loss: 2.2572, val_accuracy: 19.6667\n","Epoch 10/50: train_loss: 2.5959, train_accuracy: 9.3889, val_loss: 2.2552, val_accuracy: 24.0000\n","Epoch 11/50: train_loss: 2.5691, train_accuracy: 10.1111, val_loss: 2.3244, val_accuracy: 19.3333\n","Epoch 12/50: train_loss: 2.4595, train_accuracy: 13.3333, val_loss: 2.2307, val_accuracy: 21.0000\n","Epoch 13/50: train_loss: 2.4223, train_accuracy: 12.6667, val_loss: 2.3221, val_accuracy: 23.0000\n","Epoch 14/50: train_loss: 2.4155, train_accuracy: 14.1667, val_loss: 2.2698, val_accuracy: 21.0000\n","Epoch 15/50: train_loss: 2.3303, train_accuracy: 15.1667, val_loss: 2.3255, val_accuracy: 21.0000\n","Epoch 16/50: train_loss: 2.2712, train_accuracy: 18.6111, val_loss: 2.3996, val_accuracy: 17.3333\n","Epoch 17/50: train_loss: 2.3024, train_accuracy: 17.0556, val_loss: 2.4669, val_accuracy: 17.6667\n","Epoch 18/50: train_loss: 2.2664, train_accuracy: 17.7778, val_loss: 2.2710, val_accuracy: 24.6667\n","Epoch 19/50: train_loss: 2.1735, train_accuracy: 20.7222, val_loss: 2.3389, val_accuracy: 22.0000\n","Epoch 20/50: train_loss: 2.2285, train_accuracy: 20.2222, val_loss: 2.4293, val_accuracy: 21.6667\n","Epoch 21/50: train_loss: 2.2180, train_accuracy: 19.8889, val_loss: 2.4402, val_accuracy: 16.6667\n","Epoch 22/50: train_loss: 2.1582, train_accuracy: 21.1111, val_loss: 2.3656, val_accuracy: 20.6667\n","Epoch 23/50: train_loss: 2.1155, train_accuracy: 23.3889, val_loss: 2.4792, val_accuracy: 19.3333\n","Epoch 24/50: train_loss: 2.3179, train_accuracy: 14.8333, val_loss: 2.4825, val_accuracy: 18.0000\n","Epoch 25/50: train_loss: 2.1961, train_accuracy: 21.1667, val_loss: 2.4366, val_accuracy: 26.0000\n","Epoch 26/50: train_loss: 2.0378, train_accuracy: 27.1667, val_loss: 2.4953, val_accuracy: 24.3333\n","Epoch 27/50: train_loss: 2.0992, train_accuracy: 25.5000, val_loss: 2.3500, val_accuracy: 22.6667\n","Epoch 28/50: train_loss: 1.9292, train_accuracy: 30.0000, val_loss: 2.4057, val_accuracy: 22.3333\n","Epoch 29/50: train_loss: 1.9129, train_accuracy: 28.1667, val_loss: 2.3741, val_accuracy: 24.6667\n","Epoch 30/50: train_loss: 1.9051, train_accuracy: 29.2222, val_loss: 2.5304, val_accuracy: 22.0000\n","Epoch 31/50: train_loss: 1.8674, train_accuracy: 32.1111, val_loss: 2.5158, val_accuracy: 25.0000\n","Epoch 32/50: train_loss: 1.8268, train_accuracy: 32.3333, val_loss: 2.4507, val_accuracy: 24.6667\n","Epoch 33/50: train_loss: 1.8058, train_accuracy: 34.1667, val_loss: 2.4643, val_accuracy: 23.6667\n","Epoch 34/50: train_loss: 1.7998, train_accuracy: 35.0556, val_loss: 2.5504, val_accuracy: 21.3333\n","Epoch 35/50: train_loss: 1.7620, train_accuracy: 36.8889, val_loss: 2.5393, val_accuracy: 27.6667\n","Epoch 36/50: train_loss: 1.7823, train_accuracy: 34.9444, val_loss: 2.5255, val_accuracy: 25.3333\n","Epoch 37/50: train_loss: 1.9151, train_accuracy: 29.0556, val_loss: 2.7642, val_accuracy: 20.6667\n","Epoch 38/50: train_loss: 1.7282, train_accuracy: 37.7222, val_loss: 2.6613, val_accuracy: 22.3333\n","Epoch 39/50: train_loss: 1.6293, train_accuracy: 42.0000, val_loss: 2.8927, val_accuracy: 23.3333\n","Epoch 40/50: train_loss: 1.6755, train_accuracy: 39.9444, val_loss: 2.7114, val_accuracy: 27.3333\n","Epoch 41/50: train_loss: 1.6104, train_accuracy: 39.6111, val_loss: 2.7977, val_accuracy: 23.3333\n","Epoch 42/50: train_loss: 1.5217, train_accuracy: 43.8889, val_loss: 2.9512, val_accuracy: 27.3333\n","Epoch 43/50: train_loss: 1.6132, train_accuracy: 43.1111, val_loss: 3.2830, val_accuracy: 20.6667\n","Epoch 44/50: train_loss: 1.5555, train_accuracy: 46.5000, val_loss: 2.6670, val_accuracy: 25.0000\n","Epoch 45/50: train_loss: 1.4371, train_accuracy: 46.3889, val_loss: 2.8220, val_accuracy: 24.0000\n","Epoch 46/50: train_loss: 1.4613, train_accuracy: 50.4444, val_loss: 2.9809, val_accuracy: 24.3333\n","Epoch 47/50: train_loss: 1.4148, train_accuracy: 47.0000, val_loss: 3.3808, val_accuracy: 23.3333\n","Epoch 48/50: train_loss: 1.4637, train_accuracy: 48.2222, val_loss: 2.9445, val_accuracy: 20.6667\n","Epoch 49/50: train_loss: 1.3331, train_accuracy: 52.3889, val_loss: 3.0508, val_accuracy: 22.0000\n","Epoch 50/50: train_loss: 1.3481, train_accuracy: 50.6667, val_loss: 2.9744, val_accuracy: 26.6667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7UQBmZGWPlKK","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","    \n","class Conv1DNet2(nn.Module):\n","    \n","    def __init__(self):\n","        super(Conv1DNet2, self).__init__()\n","        self.conv = nn.Sequential(\n","          # input: 1x216x216\n","          nn.Conv2d(1, 128, (5,1)),\n","          # output: 128x212x216\n","          nn.BatchNorm2d(128,momentum=0.9),\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2),\n","          nn.Dropout(0.5),\n","          # output: 128x106x108\n","          nn.Conv2d(128, 64, (5,1)),\n","          # output: 64x102x108\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2),\n","          nn.Dropout(0.5),\n","          # output: 64x51x54\n","          nn.Conv2d(64, 64, (4,1)),\n","          # output: 64x48x54\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d(2),\n","          nn.Dropout(0.5),\n","          # output: 64x24x27\n","          nn.Conv2d(64, 64, (5,1)),\n","          # output: 64x20x27\n","          nn.BatchNorm2d(64,momentum=0.9),\n","          nn.LeakyReLU(0.2),\n","          nn.MaxPool2d((2,1), (2,1)),\n","          nn.Dropout(0.5)\n","          # output: 64x10x27\n","        )\n","        self.fc = nn.Sequential(\n","          nn.Linear(64*10*27,364),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(364,192),\n","          nn.LeakyReLU(0.2),\n","          nn.Dropout(0.5),\n","          nn.Linear(192,10)\n","        )\n","    \n","    def forward(self, input):\n","        output = self.conv(input)\n","        output = output.view(output.size(0), 64*10*27)\n","        output = self.fc(output)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuYB183LwaOe","colab_type":"code","colab":{}},"source":["model_conv = Conv1DNet2()\n","model_conv = model_conv.to(device)\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(model_conv.parameters(), lr=learning_rate)\n","n_epochs = 50\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Biqvq6nw8FK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":935},"outputId":"d8ca5dc8-6f73-44b0-c956-271c3dcbf9d2","executionInfo":{"status":"ok","timestamp":1557412418273,"user_tz":-120,"elapsed":888722,"user":{"displayName":"Thomas Schaller","photoUrl":"","userId":"04727138696451947462"}}},"source":["val_loss, val_accuracy = fit(train_dataloader, val_dataloader, model_conv, optimizer, loss_fn, n_epochs)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/50: train_loss: 4.9229, train_accuracy: 8.8333, val_loss: 3.0059, val_accuracy: 11.3333\n","Epoch 2/50: train_loss: 4.1209, train_accuracy: 1.5000, val_loss: 2.4752, val_accuracy: 10.3333\n","Epoch 3/50: train_loss: 3.0351, train_accuracy: 3.2222, val_loss: 2.3286, val_accuracy: 11.0000\n","Epoch 4/50: train_loss: 2.4893, train_accuracy: 4.8333, val_loss: 2.2777, val_accuracy: 11.6667\n","Epoch 5/50: train_loss: 2.4281, train_accuracy: 4.5556, val_loss: 2.2527, val_accuracy: 16.6667\n","Epoch 6/50: train_loss: 2.3860, train_accuracy: 6.3889, val_loss: 2.2538, val_accuracy: 14.0000\n","Epoch 7/50: train_loss: 2.3800, train_accuracy: 6.2222, val_loss: 2.2387, val_accuracy: 15.6667\n","Epoch 8/50: train_loss: 2.3648, train_accuracy: 6.8889, val_loss: 2.2352, val_accuracy: 18.0000\n","Epoch 9/50: train_loss: 2.3630, train_accuracy: 8.0000, val_loss: 2.2116, val_accuracy: 19.6667\n","Epoch 10/50: train_loss: 2.3338, train_accuracy: 9.2222, val_loss: 2.2066, val_accuracy: 19.0000\n","Epoch 11/50: train_loss: 2.3424, train_accuracy: 8.3333, val_loss: 2.2103, val_accuracy: 16.3333\n","Epoch 12/50: train_loss: 2.3145, train_accuracy: 10.2778, val_loss: 2.1858, val_accuracy: 20.6667\n","Epoch 13/50: train_loss: 2.2990, train_accuracy: 11.6111, val_loss: 2.1485, val_accuracy: 25.0000\n","Epoch 14/50: train_loss: 2.2749, train_accuracy: 13.2778, val_loss: 2.1251, val_accuracy: 25.0000\n","Epoch 15/50: train_loss: 2.2523, train_accuracy: 13.5556, val_loss: 2.1569, val_accuracy: 24.6667\n","Epoch 16/50: train_loss: 2.2280, train_accuracy: 15.8889, val_loss: 2.1812, val_accuracy: 19.6667\n","Epoch 17/50: train_loss: 2.2298, train_accuracy: 15.7222, val_loss: 2.1000, val_accuracy: 23.3333\n","Epoch 18/50: train_loss: 2.1778, train_accuracy: 16.8333, val_loss: 2.1096, val_accuracy: 28.0000\n","Epoch 19/50: train_loss: 2.1729, train_accuracy: 18.5000, val_loss: 2.1627, val_accuracy: 21.6667\n","Epoch 20/50: train_loss: 2.0910, train_accuracy: 22.5556, val_loss: 2.1564, val_accuracy: 22.3333\n","Epoch 21/50: train_loss: 2.0779, train_accuracy: 21.5000, val_loss: 2.1104, val_accuracy: 24.6667\n","Epoch 22/50: train_loss: 2.1025, train_accuracy: 20.5556, val_loss: 2.1063, val_accuracy: 31.0000\n","Epoch 23/50: train_loss: 2.1088, train_accuracy: 23.5000, val_loss: 2.2299, val_accuracy: 18.6667\n","Epoch 24/50: train_loss: 2.0076, train_accuracy: 26.0556, val_loss: 2.0197, val_accuracy: 27.3333\n","Epoch 25/50: train_loss: 1.9203, train_accuracy: 26.9444, val_loss: 2.0954, val_accuracy: 28.0000\n","Epoch 26/50: train_loss: 1.9359, train_accuracy: 29.0000, val_loss: 2.2337, val_accuracy: 23.6667\n","Epoch 27/50: train_loss: 2.1408, train_accuracy: 21.4444, val_loss: 2.0866, val_accuracy: 26.6667\n","Epoch 28/50: train_loss: 1.9175, train_accuracy: 30.3333, val_loss: 2.0823, val_accuracy: 29.3333\n","Epoch 29/50: train_loss: 1.8439, train_accuracy: 30.4444, val_loss: 2.0392, val_accuracy: 31.3333\n","Epoch 30/50: train_loss: 1.7927, train_accuracy: 35.4444, val_loss: 2.0419, val_accuracy: 30.3333\n","Epoch 31/50: train_loss: 1.7321, train_accuracy: 34.2222, val_loss: 2.0483, val_accuracy: 29.6667\n","Epoch 32/50: train_loss: 1.8164, train_accuracy: 31.0000, val_loss: 2.1615, val_accuracy: 25.3333\n","Epoch 33/50: train_loss: 1.8430, train_accuracy: 34.3333, val_loss: 2.1811, val_accuracy: 30.3333\n","Epoch 34/50: train_loss: 1.8379, train_accuracy: 31.9444, val_loss: 2.0931, val_accuracy: 31.6667\n","Epoch 35/50: train_loss: 1.8811, train_accuracy: 29.0000, val_loss: 2.1776, val_accuracy: 27.6667\n","Epoch 36/50: train_loss: 1.6723, train_accuracy: 41.2778, val_loss: 2.1507, val_accuracy: 27.3333\n","Epoch 37/50: train_loss: 1.6547, train_accuracy: 37.2778, val_loss: 2.0406, val_accuracy: 28.0000\n","Epoch 38/50: train_loss: 1.6906, train_accuracy: 38.0556, val_loss: 2.2452, val_accuracy: 26.0000\n","Epoch 39/50: train_loss: 1.7763, train_accuracy: 37.3889, val_loss: 1.9956, val_accuracy: 33.6667\n","Epoch 40/50: train_loss: 1.7078, train_accuracy: 35.3333, val_loss: 2.2201, val_accuracy: 33.0000\n","Epoch 41/50: train_loss: 1.6173, train_accuracy: 39.7778, val_loss: 2.1318, val_accuracy: 32.6667\n","Epoch 42/50: train_loss: 1.4269, train_accuracy: 48.0556, val_loss: 2.0166, val_accuracy: 36.0000\n","Epoch 43/50: train_loss: 1.4331, train_accuracy: 46.3889, val_loss: 2.0136, val_accuracy: 37.3333\n","Epoch 44/50: train_loss: 1.3845, train_accuracy: 47.1667, val_loss: 2.1000, val_accuracy: 34.3333\n","Epoch 45/50: train_loss: 1.3707, train_accuracy: 49.1667, val_loss: 2.0850, val_accuracy: 34.3333\n","Epoch 46/50: train_loss: 1.3996, train_accuracy: 47.8889, val_loss: 2.0046, val_accuracy: 31.6667\n","Epoch 47/50: train_loss: 1.4059, train_accuracy: 49.5000, val_loss: 2.0116, val_accuracy: 37.6667\n","Epoch 48/50: train_loss: 1.3839, train_accuracy: 50.3333, val_loss: 2.4916, val_accuracy: 29.6667\n","Epoch 49/50: train_loss: 1.3457, train_accuracy: 48.3333, val_loss: 2.2197, val_accuracy: 30.6667\n","Epoch 50/50: train_loss: 1.4444, train_accuracy: 45.2778, val_loss: 2.2166, val_accuracy: 29.6667\n"],"name":"stdout"}]}]}